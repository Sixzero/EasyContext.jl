- Use Jina embedder. 
- get_context should not return the concatenated context, because of unique filtering.

We could increase and decrease the backtick count right? and I would also maybe make a name for the elseif functions like is_opener_ticks and is_closer_ticks. We would need for the outter opener to also allow simply 3 backtick openers without language specification, but any next opener is only an opener if there is lanauge specification otherwise it is a closer, which decreases the nesting level.

#%%

# function llm_context_planner(ctx, tools)
#   response = ai"""
#   What tools do you think you going to need to solve the query:
#   <tools>
#     $tools
#   </tools
#   <query>
#     $ctx
#   </query>
#   """
#   parse_tools(response)
# end

# results = llm_context_planner(ctx=ctx_question, tools=[
#   (:julia_context => "Tool description" => julia_context),
#   (:google_search => "") 
#   ])
#%%
We need to implement the  get_next_msg_contrcutor(::Conversation) and then the ConversationCTX and BetterConversationCTX should just use that.
#%%
Check out the AgeTracker and the Conversation files, and correct the BetterContextCTX tests with the new ideas.
This is the new use of the age things:

function start_conversation(user_question=""; resume, streaming, project_paths, logdir, show_tokens, silent, loop=true)
  
  # init
  workspace_context = init_workspace_context(project_paths)
  julia_context     = init_julia_context()
  conv_ctx          = init_conversation_context(SYSTEM_PROMPT(ChatSH), shell_format_description(), workspace_format_description(), julia_format_description())
  age_tracker       = AgeTracker(max_history=14, cut_to=6)
  
  question_acc      = QuestionCTX()
  extractor         = CodeBlockExtractor()
  persister         = Persistable(logdir)

  # prepare 
  print_project_tree(workspace_context.workspace, show_tokens=show_tokens)
  set_terminal_title("AISH $(workspace_context.workspace.common_path)")
  !silent && greet(ChatSH)
  !silent && isempty(user_question) && (isdefined(Base, :active_repl) ? println("Your first [Enter] will just interrupt the REPL line and get into the conversation after that: ") : println("Your multiline input (empty line to finish):"))

  # forward
  while loop || !isempty(user_question)

    user_question = isempty(user_question) ? wait_user_question(user_question) : user_question
    !silent && println("Thinking...")  # Only print if not silent

    ctx_question = user_question |> question_acc 
    ctx_shell    = extractor |> shell_ctx_2_string
    ctx_codebase = @async_showerr process_workspace_context(workspace_context, ctx_question; age_tracker)
    ctx_jl_pkg   = @async_showerr process_julia_context(julia_context, ctx_question; age_tracker)

    query = context_combiner!(
      user_question, 
      ctx_shell, 
      fetch(ctx_codebase), 
      fetch(ctx_jl_pkg),
    )

    conv_ctx(create_user_message(query))

    reset!(extractor)
    user_question = ""

    cache = get_cache_setting(workspace_context.ws_age, conv_ctx)
    error = LLM_solve(conv_ctx, cache;
                      on_text     = (text)   -> extract_and_preprocess_codeblocks(text, extractor, preprocess=(cb)->LLM_conditonal_apply_changes(cb)),
                      on_meta_usr = (meta)   -> update_last_user_message_meta(conv_ctx, meta),
                      on_meta_ai  = (ai_msg) -> conv_ctx(ai_msg),
                      on_done     = ()       -> codeblock_runner(extractor),
                      on_error    = (error)  -> add_error_message!(conv_ctx,"ERROR: $error"),
    )

    cut_old_history!(age_tracker, conv_ctx, julia_context, workspace_context, )

    silent && break
  end
end
